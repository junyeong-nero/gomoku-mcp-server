import os
import sys
import json
import asyncio
from typing import Any
from openai import OpenAI

from fastmcp.client import Client

# --- ì„¤ì • ---

# 1. OpenRouter API í‚¤ ì„¤ì •
api_key = os.environ.get("OPENROUTER_API_KEY")
if not api_key:
    print("âŒ ì˜¤ë¥˜: OPENROUTER_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# 2. OpenRouter í´ë¼ì´ì–¸íŠ¸ ìƒì„±
openrouter_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=api_key,
)

# 3. ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ ì„¤ì •
MODEL_NAME = "google/gemini-2.5-flash"


def to_openai_schema(tool) -> dict:
    """
    FastMCP ë„êµ¬ë¥¼ OpenAI/OpenRouter í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    raw_schema = (
        getattr(tool, "inputSchema", None)
        or getattr(tool, "input_schema", None)
        or getattr(tool, "parameters", None)
    )

    if raw_schema is None:
        schema: dict = {
            "type": "object",
            "properties": {},
            "additionalProperties": True,
        }

    elif isinstance(raw_schema, dict):
        schema = raw_schema

    elif hasattr(raw_schema, "model_json_schema"):
        schema = raw_schema.model_json_schema()

    elif isinstance(raw_schema, list):
        props, required = {}, []
        for p in raw_schema:
            props[p["name"]] = {
                "type": p["type"],
                "description": p.get("description", ""),
            }
            if p.get("required", True):
                required.append(p["name"])
        schema = {"type": "object", "properties": props}
        if required:
            schema["required"] = required

    else:
        schema = {"type": "object", "properties": {}, "additionalProperties": True}

    schema.setdefault("type", "object")
    schema.setdefault("properties", {})
    if "required" not in schema:
        schema["required"] = list(schema["properties"].keys())

    # OpenRouterê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    return {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": getattr(tool, "description", ""),
            "parameters": schema,
        },
    }


async def run_gomoku_agent():
    """OpenRouterì™€ FastMCPë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ëª© ê²Œì„ì„ í”Œë ˆì´í•˜ëŠ” ì—ì´ì „íŠ¸"""
    try:
        mcp_client = Client("src/server.py")
        print(f"âœ… Gomoku ì„œë²„ í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: Gomoku ì„œë²„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì—ëŸ¬ ìƒì„¸: {e}")
        return

    # async with ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    async with mcp_client:
        # FastMCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë„êµ¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        mcp_tools = await mcp_client.list_tools()

        # MCP í˜•ì‹ì„ OpenAI/OpenRouter í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        gomoku_tools = [to_openai_schema(tool) for tool in mcp_tools]

        print("âœ… Gomoku ì„œë²„ë¡œë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜(Tools) ëª©ë¡ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        print(f"   ë³€í™˜ëœ ë„êµ¬ ê°œìˆ˜: {len(gomoku_tools)}")

    # async with ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    async with mcp_client:
        # FastMCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ OpenAI í˜¸í™˜ í˜•ì‹ì˜ tool ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        gomoku_tools = await mcp_client.list_tools()
        print("âœ… Gomoku ì„œë²„ë¡œë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜(Tools) ëª©ë¡ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

        print("\n==============================================")
        print(f"   Gomoku AI Agent (Model: {MODEL_NAME})   ")
        print("==============================================")
        print("ì˜¤ëª© ê²Œì„ì— ëŒ€í•œ ëª…ë ¹ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
        print("ì˜ˆ: 'ê²Œì„ ì‹œì‘í•´ì¤˜', 'ì§€ê¸ˆ ë³´ë“œ ìƒíƒœ ë³´ì—¬ì¤˜', '7, 7ì— ëŒì„ ë†”ì¤˜'")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        # ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
        messages = [
            {
                "role": "system",
                "content": "You are a helpful assistant that plays a game of Gomoku using the provided tools.",
            }
        ]

        while True:
            # asyncio-compatible input
            prompt = await asyncio.get_event_loop().run_in_executor(
                None, input, "\nğŸ‘¤ You: "
            )

            if prompt.lower() in ["quit", "exit"]:
                print("ğŸ¤– Agent: ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            messages.append({"role": "user", "content": prompt})

            try:
                # 1. OpenRouterì— ì²« ë²ˆì§¸ ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
                response = openrouter_client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=messages,
                    tools=gomoku_tools,
                    tool_choice="auto",
                )

                # ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬
                if not response or not response.choices or len(response.choices) == 0:
                    print(f"âŒ API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {response}")
                    messages.pop()
                    continue

                response_message = response.choices[0].message

                # 2. ëª¨ë¸ì´ í•¨ìˆ˜ í˜¸ì¶œì„ ê²°ì •í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                if response_message.tool_calls:
                    messages.append(response_message)

                    for tool_call in response_message.tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)

                        print(f"âš¡ï¸ Calling function: {function_name}({function_args})")

                        try:
                            function_to_call = getattr(mcp_client, function_name)
                            # awaitë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
                            function_response = await function_to_call(**function_args)
                        except Exception as e:
                            print(f"    - Function call error: {e}")
                            function_response = f"Error executing function: {e}"

                        messages.append(
                            {
                                "tool_call_id": tool_call.id,
                                "role": "tool",
                                "name": function_name,
                                "content": str(function_response),
                            }
                        )

                    # 3. í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ OpenRouterì— ë‘ ë²ˆì§¸ ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
                    second_response = openrouter_client.chat.completions.create(
                        model=MODEL_NAME,
                        messages=messages,
                    )

                    # ë‘ ë²ˆì§¸ ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬
                    if (
                        not second_response
                        or not second_response.choices
                        or len(second_response.choices) == 0
                    ):
                        print(f"âŒ ë‘ ë²ˆì§¸ API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        continue

                    final_response = second_response.choices[0].message.content

                    if not final_response:
                        print("âŒ ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        continue

                    messages.append({"role": "assistant", "content": final_response})
                    print(f"ğŸ¤– Agent: {final_response}")

                else:
                    final_response = response_message.content
                    messages.append({"role": "assistant", "content": final_response})
                    print(f"ğŸ¤– Agent: {final_response}")

            except Exception as e:
                print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                import traceback

                traceback.print_exc()
                if messages and messages[-1]["role"] == "user":
                    messages.pop()


if __name__ == "__main__":
    asyncio.run(run_gomoku_agent())
